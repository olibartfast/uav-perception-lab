# UAV Perception Lab ğŸšğŸ‘ï¸

A progressive hands-on training repo to build computer vision, sensor fusion, and real-time perception skills for UAVs.

## ğŸ“Œ Roadmap
This repo follows a 6-phase curriculum:
1. Camera calibration & stereo depth
2. Object detection & tracking
3. Embedded AI acceleration
4. Sensor fusion (EKF, VIO)
5. Multi-drone triangulation (simulation)
6. Real drone perception tests

## ğŸ§° Tools
- OpenCV, ROS 2, PX4, AirSim
- PyTorch / YOLOv8
- TensorRT / CUDA
- FilterPy (for Kalman/Extended KF)
- VINS-Mono / ORB-SLAM3

## ğŸ“‚ Structure
See each `phaseX_*/` folder for code, datasets, and notes.

## ğŸ¯ Progress Tracker
- [ ] Phase 1: Calibration & Stereo
- [ ] Phase 2: Detection & Tracking
- [ ] Phase 3: Embedded Acceleration
- [ ] Phase 4: Sensor Fusion
- [ ] Phase 5: Multi-Drone Sim
- [ ] Phase 6: Real Drone Tests
